{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Example Classification Pipelines",
   "id": "6afe7e49ae02e78e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:57:10.378285Z",
     "start_time": "2025-10-14T10:57:10.047020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import opencortex.neuroengine.flux.base.operators  # Enable >>\n",
    "from opencortex.neuroengine.flux.estimation.onnx import ONNXNode\n",
    "from opencortex.neuroengine.flux.preprocessing.bandpass import BandPassFilterNode\n",
    "from opencortex.neuroengine.flux.preprocessing.notch import NotchFilterNode\n",
    "from opencortex.utils.loader import load_data, convert_to_mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fs = 250\n",
    "chs = [\"Fz\", \"C3\", \"Cz\", \"C4\", \"Pz\", \"PO7\", \"Oz\", \"PO8\"]\n",
    "\n",
    "\n",
    "eeg, trigger, dataframe = load_data(\"../data/aep/auditory_erp_eyes_open_S1.csv\", fs=fs, skiprows=5, delimiter=',')\n",
    "print(\"Loaded data with shape:\" + str(eeg.shape) + \" and trigger shape: \" + str(trigger.shape))\n",
    "print(\"That means we have \" + str(eeg.shape[0]) + \" samples and \" + str(eeg.shape[1]) + \" channels.\")\n",
    "\n",
    " # Convert to MNE format\n",
    "raw_data_train = convert_to_mne(eeg, trigger, fs=fs, chs=chs, recompute=False) # recompute=True to recalculate the event labels if the values are negative\n",
    "\n",
    "eeg, trigger, dataframe = load_data(\"../data/aep/auditory_erp_eyes_closed_S1.csv\", fs=fs, skiprows=5, delimiter=',')\n",
    "print(\"Loaded data with shape:\" + str(eeg.shape) + \" and trigger shape: \" + str(trigger.shape))\n",
    "print(\"That means we have \" + str(eeg.shape[0]) + \" samples and \" + str(eeg.shape[1]) + \" channels.\")\n",
    "\n",
    "raw_data_test = convert_to_mne(eeg, trigger, fs=fs, chs=chs, recompute=False)"
   ],
   "id": "cba5504343074a67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with shape:(13626, 8) and trigger shape: (13626,)\n",
      "That means we have 13626 samples and 8 channels.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=13626\n",
      "    Range : 0 ... 13625 =      0.000 ...    54.500 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=13626\n",
      "    Range : 0 ... 13625 =      0.000 ...    54.500 secs\n",
      "Ready.\n",
      "Loaded data with shape:(14159, 8) and trigger shape: (14159,)\n",
      "That means we have 14159 samples and 8 channels.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=14159\n",
      "    Range : 0 ... 14158 =      0.000 ...    56.632 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=14159\n",
      "    Range : 0 ... 14158 =      0.000 ...    56.632 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:57:10.471719Z",
     "start_time": "2025-10-14T10:57:10.442169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class SimpleEEGNet(pl.LightningModule):\n",
    "    def __init__(self, n_channels=8, n_times=250, n_classes=2, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = lr\n",
    "\n",
    "        self.conv1 = nn.Conv1d(n_channels, 32, 5, padding=2)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, 5, padding=2)\n",
    "        self.fc = nn.Linear(64 * (n_times // 4), n_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        acc = (logits.argmax(1) == y).float().mean()\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x = batch[0] if isinstance(batch, (list, tuple)) else batch\n",
    "        return self(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ],
   "id": "ce2044b5ac305d35",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:57:10.534196Z",
     "start_time": "2025-10-14T10:57:10.505671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def export_to_onnx(\n",
    "    model: torch.nn.Module,\n",
    "    output_path: str,\n",
    "    input_shape: tuple,\n",
    "    device: str = 'cpu',\n",
    "    opset_version: int = 11,\n",
    "    verify: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Export PyTorch model to ONNX format.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model (or Lightning module)\n",
    "        output_path: Path to save ONNX file\n",
    "        input_shape: Shape of input tensor (e.g., (1, 8, 250))\n",
    "        device: Device to run model on\n",
    "        opset_version: ONNX opset version\n",
    "        verify: If True, verify exported model with ONNX Runtime\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import numpy as np\n",
    "\n",
    "    # Move model to device and set to eval mode\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Create dummy input\n",
    "    dummy_input = torch.randn(*input_shape).to(device)\n",
    "\n",
    "    # Export to ONNX\n",
    "    print(f\"Exporting model to {output_path}...\")\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        output_path,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={\n",
    "            'input': {0: 'batch_size'},\n",
    "            'output': {0: 'batch_size'}\n",
    "        },\n",
    "        opset_version=opset_version,\n",
    "        export_params=True,\n",
    "        do_constant_folding=True\n",
    "    )\n",
    "\n",
    "    print(f\"âœ“ Model exported to {output_path}\")\n",
    "\n",
    "    # Verify with ONNX Runtime\n",
    "    if verify:\n",
    "        try:\n",
    "            import onnxruntime as ort\n",
    "\n",
    "            print(\"Verifying exported model...\")\n",
    "            ort_session = ort.InferenceSession(output_path)\n",
    "\n",
    "            # Test inference\n",
    "            test_input = np.random.randn(*input_shape).astype(np.float32)\n",
    "            ort_outputs = ort_session.run(None, {'input': test_input})\n",
    "\n",
    "            # Compare with PyTorch\n",
    "            with torch.no_grad():\n",
    "                torch_output = model(torch.from_numpy(test_input).to(device))\n",
    "                torch_output = torch_output.cpu().numpy()\n",
    "\n",
    "            # Check if outputs match\n",
    "            max_diff = np.max(np.abs(ort_outputs[0] - torch_output))\n",
    "            print(f\"Max difference between PyTorch and ONNX: {max_diff:.6f}\")\n",
    "\n",
    "            if max_diff < 1e-5:\n",
    "                print(\"âœ“ ONNX model verified successfully!\")\n",
    "            else:\n",
    "                print(\"âš  Warning: Outputs differ slightly (this is often normal)\")\n",
    "\n",
    "        except ImportError:\n",
    "            print(\"âš  onnxruntime not installed, skipping verification\")\n",
    "            print(\"Install with: pip install onnxruntime\")"
   ],
   "id": "b5d44867f1e241af",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:57:42.599307Z",
     "start_time": "2025-10-14T10:57:10.566534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from opencortex.neuroengine.flux.estimation.lightning import LightningNode\n",
    "from opencortex.neuroengine.flux.preprocessing.dataset import DatasetNode\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from opencortex.neuroengine.flux.preprocessing.scaler import ScalerNode\n",
    "from opencortex.neuroengine.flux.preprocessing.extract import ExtractNode\n",
    "from opencortex.neuroengine.flux.preprocessing.epochs import EpochingNode\n",
    "from opencortex.neuroengine.flux.preprocessing.events import ExtractEventsNode, FilterEventsNode, RelabelEventsNode\n",
    "from opencortex.neuroengine.flux.base.sequential import Sequential\n",
    "\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"logs/\")\n",
    "\n",
    "preprocessing = Sequential(\n",
    "    NotchFilterNode((50, 60), name='NotchFilter'),\n",
    "    BandPassFilterNode(0.1, 30.0, name='BandPassFilter'),\n",
    "    ExtractEventsNode(stim_channel='STI', auto_label=True, name='ExtractEvents'),\n",
    "    FilterEventsNode(max_event_id=90, name='FilterEvents'),\n",
    "    RelabelEventsNode(target_class=1, nontarget_label=3, name='RelabelEvents'),\n",
    "    EpochingNode(tmin=-0.2, tmax=0.8, baseline=(-0.1, 0.0), event_id={'T': 1, 'NT': 3}, name='Epoching'),\n",
    "    ExtractNode(label_encoder=LabelEncoder(), apply_label_encoding=True, label_mapping={1: 0, 3: 1}, name='XyExtractor'),\n",
    "    ScalerNode(scaler=StandardScaler(), per_channel=True, name='StdScaler'),\n",
    "    DatasetNode(split_size=0.2, batch_size=8, shuffle=True, num_workers=4, name='Dataset'),\n",
    "    LightningNode(\n",
    "            model=SimpleEEGNet(n_channels=len(chs), n_times=250),\n",
    "            trainer_config={\n",
    "                'max_epochs': 5,\n",
    "                'accelerator': 'cpu',\n",
    "                'enable_progress_bar': True,\n",
    "                'enable_model_summary': True,\n",
    "                'log_every_n_steps': 1,\n",
    "                'logger': tb_logger,\n",
    "            },\n",
    "            name='SimpleEEGNet'\n",
    "        ),\n",
    "    name=\"Preprocessing\"\n",
    ")\n",
    "\n",
    "trained_model = preprocessing(raw_data_train)\n"
   ],
   "id": "917119d59139739b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:l_trans_bandwidth must be less than h_freq, setting it to l_freq:0.1Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 3.50 Hz\n",
      "- Upper transition bandwidth: 3.50 Hz\n",
      "- Filter length: 237 samples (0.948 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 31.50 Hz)\n",
      "- Filter length: 8251 samples (33.004 s)\n",
      "\n",
      "Finding events on: STI\n",
      "90 events found on stim channel STI\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "90 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 90 events and 251 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | conv1     | Conv1d           | 1.3 K  | train\n",
      "1 | pool      | MaxPool1d        | 0      | train\n",
      "2 | conv2     | Conv1d           | 10.3 K | train\n",
      "3 | fc        | Linear           | 7.9 K  | train\n",
      "4 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "19.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.6 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\Desktop\\projects\\OpenCortexBCI\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:428: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\Desktop\\projects\\OpenCortexBCI\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:428: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.64it/s, v_num=9]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00, 74.82it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 91.05it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 96.88it/s]\u001B[A\n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.13it/s, v_num=9]       \u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00, 77.91it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 100.80it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 85.70it/s] \u001B[A\n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.83it/s, v_num=9]       \u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00, 66.57it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 24.80it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 34.47it/s]\u001B[A\n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.62it/s, v_num=9]       \u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00, 98.76it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 119.73it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 124.72it/s]\u001B[A\n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.45it/s, v_num=9]        \u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00, 86.62it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 105.13it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 119.87it/s]\u001B[A\n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:05<00:00,  1.74it/s, v_num=9]        \u001B[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:05<00:00,  1.73it/s, v_num=9]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:57:42.691416Z",
     "start_time": "2025-10-14T10:57:42.632630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = \"example_eegnet.pth\"\n",
    "lightning_node = preprocessing.get_node(\"SimpleEEGNet\")\n",
    "lightning_node.save_checkpoint(model_path)"
   ],
   "id": "395b8a04bda61e4",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:57:42.895136Z",
     "start_time": "2025-10-14T10:57:42.724576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Usage\n",
    "model = SimpleEEGNet(n_channels=len(chs), n_times=250, n_classes=2)\n",
    "#model.load_state_dict(torch.load('example_eegnet.pth'))\n",
    "\n",
    "export_to_onnx(\n",
    "    model=trained_model,\n",
    "    output_path='model.onnx',\n",
    "    input_shape=(1, 8, 250),  # (batch, channels, time)\n",
    "    verify=True,\n",
    ")"
   ],
   "id": "5d9357441ee58617",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting model to model.onnx...\n",
      "âœ“ Model exported to model.onnx\n",
      "Verifying exported model...\n",
      "Max difference between PyTorch and ONNX: 0.000000\n",
      "âœ“ ONNX model verified successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_57692\\92157656.py:32: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:57:46.874302Z",
     "start_time": "2025-10-14T10:57:42.927594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from opencortex.neuroengine.flux.evaluation.metrics import MetricNode\n",
    "from opencortex.neuroengine.flux.estimation.onnx import ONNXNode\n",
    "\n",
    "fitted_scaler = preprocessing.get_node(\"StdScaler\")\n",
    "extractor_node = preprocessing.get_node(\"XyExtractor\")\n",
    "\n",
    "\n",
    "inference_pipeline = Sequential(\n",
    "    NotchFilterNode((50, 60), name='NotchFilter'),\n",
    "    BandPassFilterNode(0.1, 30.0, name='BandPassFilter'),\n",
    "    ExtractEventsNode(stim_channel='STI', auto_label=True, name='ExtractEvents'),\n",
    "    FilterEventsNode(max_event_id=90, name='FilterEvents'),\n",
    "    RelabelEventsNode(target_class=1, nontarget_label=3, name='RelabelEvents'),\n",
    "    EpochingNode(tmin=-0.2, tmax=0.8, baseline=(-0.1, 0.0), event_id={'T': 1, 'NT': 3}, name='Epoching'),\n",
    "    extractor_node,\n",
    "    fitted_scaler,\n",
    "    DatasetNode(split_size=0.0, batch_size=1, shuffle=False, num_workers=4, name='TestDataset'),\n",
    "    ONNXNode(model_path='model.onnx', name='ONNXInference'),\n",
    "    name=\"Inference\",\n",
    "\n",
    ")\n",
    "\n",
    "predictions = inference_pipeline(raw_data_test)\n",
    "predictions\n"
   ],
   "id": "df0297a659f17bd8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:l_trans_bandwidth must be less than h_freq, setting it to l_freq:0.1Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 3.50 Hz\n",
      "- Upper transition bandwidth: 3.50 Hz\n",
      "- Filter length: 237 samples (0.948 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 31.50 Hz)\n",
      "- Filter length: 8251 samples (33.004 s)\n",
      "\n",
      "Finding events on: STI\n",
      "90 events found on stim channel STI\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "90 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 90 events and 251 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error in Sequential node 'Inference': [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input for the following indices\n index: 2 Got: 251 Expected: 250\n Please fix either the inputs/outputs or the model.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgument\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[1;32m~\\Desktop\\projects\\OpenCortexBCI\\opencortex\\neuroengine\\flux\\base\\sequential.py:36\u001B[0m, in \u001B[0;36mSequential.__call__\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps:\n\u001B[1;32m---> 36\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\Desktop\\projects\\OpenCortexBCI\\opencortex\\neuroengine\\flux\\estimation\\onnx.py:56\u001B[0m, in \u001B[0;36mONNXNode.__call__\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# Run inference\u001B[39;00m\n\u001B[1;32m---> 56\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     57\u001B[0m predictions \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\projects\\OpenCortexBCI\\.venv\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:275\u001B[0m, in \u001B[0;36mSession.run\u001B[1;34m(self, output_names, input_feed, run_options)\u001B[0m\n\u001B[0;32m    274\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 275\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_feed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    276\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m C\u001B[38;5;241m.\u001B[39mEPFail \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[1;31mInvalidArgument\u001B[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input for the following indices\n index: 2 Got: 251 Expected: 250\n Please fix either the inputs/outputs or the model.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 23\u001B[0m\n\u001B[0;32m      5\u001B[0m extractor_node \u001B[38;5;241m=\u001B[39m preprocessing\u001B[38;5;241m.\u001B[39mget_node(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mXyExtractor\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      8\u001B[0m inference_pipeline \u001B[38;5;241m=\u001B[39m Sequential(\n\u001B[0;32m      9\u001B[0m     NotchFilterNode((\u001B[38;5;241m50\u001B[39m, \u001B[38;5;241m60\u001B[39m), name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNotchFilter\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[0;32m     10\u001B[0m     BandPassFilterNode(\u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m30.0\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBandPassFilter\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     20\u001B[0m \n\u001B[0;32m     21\u001B[0m )\n\u001B[1;32m---> 23\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43minference_pipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_data_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m predictions\n",
      "File \u001B[1;32m~\\Desktop\\projects\\OpenCortexBCI\\opencortex\\neuroengine\\flux\\base\\sequential.py:39\u001B[0m, in \u001B[0;36mSequential.__call__\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m data\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m---> 39\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError in Sequential node \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Error in Sequential node 'Inference': [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input for the following indices\n index: 2 Got: 251 Expected: 250\n Please fix either the inputs/outputs or the model."
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6eba1d3c177a8fbe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
