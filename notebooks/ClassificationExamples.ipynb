{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Example Classification Pipelines",
   "id": "6afe7e49ae02e78e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T20:32:42.617878Z",
     "start_time": "2025-10-07T20:32:39.399234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import opencortex.neuroengine.flux.base.operators  # Enable >>\n",
    "from opencortex.neuroengine.flux.preprocessing.bandpass import BandPassFilterNode\n",
    "from opencortex.neuroengine.flux.preprocessing.notch import NotchFilterNode\n",
    "from opencortex.utils.loader import load_data, convert_to_mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fs = 250\n",
    "chs = [\"Fz\", \"C3\", \"Cz\", \"C4\", \"Pz\", \"PO7\", \"Oz\", \"PO8\"]\n",
    "\n",
    "\n",
    "eeg, trigger, dataframe = load_data(\"../data/aep/auditory_erp_eyes_open_S1.csv\", fs=fs, skiprows=5, delimiter=',')\n",
    "print(\"Loaded data with shape:\" + str(eeg.shape) + \" and trigger shape: \" + str(trigger.shape))\n",
    "print(\"That means we have \" + str(eeg.shape[0]) + \" samples and \" + str(eeg.shape[1]) + \" channels.\")\n",
    "\n",
    " # Convert to MNE format\n",
    "raw_data_train = convert_to_mne(eeg, trigger, fs=fs, chs=chs, recompute=False) # recompute=True to recalculate the event labels if the values are negative\n",
    "\n",
    "eeg, trigger, dataframe = load_data(\"../data/aep/auditory_erp_eyes_closed_S1.csv\", fs=fs, skiprows=5, delimiter=',')\n",
    "print(\"Loaded data with shape:\" + str(eeg.shape) + \" and trigger shape: \" + str(trigger.shape))\n",
    "print(\"That means we have \" + str(eeg.shape[0]) + \" samples and \" + str(eeg.shape[1]) + \" channels.\")\n",
    "\n",
    "raw_data_test = convert_to_mne(eeg, trigger, fs=fs, chs=chs, recompute=False)"
   ],
   "id": "cba5504343074a67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with shape:(13626, 8) and trigger shape: (13626,)\n",
      "That means we have 13626 samples and 8 channels.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=13626\n",
      "    Range : 0 ... 13625 =      0.000 ...    54.500 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=13626\n",
      "    Range : 0 ... 13625 =      0.000 ...    54.500 secs\n",
      "Ready.\n",
      "Loaded data with shape:(14159, 8) and trigger shape: (14159,)\n",
      "That means we have 14159 samples and 8 channels.\n",
      "Creating RawArray with float64 data, n_channels=8, n_times=14159\n",
      "    Range : 0 ... 14158 =      0.000 ...    56.632 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=14159\n",
      "    Range : 0 ... 14158 =      0.000 ...    56.632 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T20:32:50.473743Z",
     "start_time": "2025-10-07T20:32:45.493062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class SimpleEEGNet(pl.LightningModule):\n",
    "    def __init__(self, n_channels=8, n_times=250, n_classes=2, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = lr\n",
    "\n",
    "        self.conv1 = nn.Conv1d(n_channels, 32, 5, padding=2)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, 5, padding=2)\n",
    "        self.fc = nn.Linear(64 * (n_times // 4), n_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        acc = (logits.argmax(1) == y).float().mean()\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x = batch[0] if isinstance(batch, (list, tuple)) else batch\n",
    "        return self(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ],
   "id": "ce2044b5ac305d35",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T20:36:11.458312Z",
     "start_time": "2025-10-07T20:34:08.709484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from opencortex.neuroengine.flux.estimation.lightning import LightningNode\n",
    "from opencortex.neuroengine.flux.preprocessing.dataset import DatasetNode\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from opencortex.neuroengine.flux.preprocessing.scaler import ScalerNode\n",
    "from opencortex.neuroengine.flux.preprocessing.extract import ExtractNode\n",
    "from opencortex.neuroengine.flux.preprocessing.epochs import EpochingNode\n",
    "from opencortex.neuroengine.flux.preprocessing.events import ExtractEventsNode, FilterEventsNode, RelabelEventsNode\n",
    "from opencortex.neuroengine.flux.base.sequential import Sequential\n",
    "\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"logs/\")\n",
    "\n",
    "preprocessing = Sequential(\n",
    "    NotchFilterNode((50, 60), name='NotchFilter'),\n",
    "    BandPassFilterNode(0.1, 30.0, name='BandPassFilter'),\n",
    "    ExtractEventsNode(stim_channel='STI', auto_label=True, name='ExtractEvents'),\n",
    "    FilterEventsNode(max_event_id=90, name='FilterEvents'),\n",
    "    RelabelEventsNode(target_class=1, nontarget_label=3, name='RelabelEvents'),\n",
    "    EpochingNode(tmin=-0.2, tmax=0.8, baseline=(-0.1, 0.0), event_id={'T': 1, 'NT': 3}, name='Epoching'),\n",
    "    ExtractNode(label_encoder=LabelEncoder(), apply_label_encoding=True, label_mapping={1: 0, 3: 1}, name='XyExtractor'),\n",
    "    ScalerNode(scaler=StandardScaler(), per_channel=True, name='StdScaler'),\n",
    "    DatasetNode(split_size=0.2, batch_size=8, shuffle=True, num_workers=4, name='Dataset'),\n",
    "    LightningNode(\n",
    "            model=SimpleEEGNet(n_channels=len(chs), n_times=250),\n",
    "            trainer_config={\n",
    "                'max_epochs': 5,\n",
    "                'accelerator': 'cpu',\n",
    "                'enable_progress_bar': True,\n",
    "                'enable_model_summary': True,\n",
    "                'log_every_n_steps': 1,\n",
    "                'logger': tb_logger,\n",
    "            },\n",
    "            name='SimpleEEGNet'\n",
    "        ),\n",
    "    name=\"Preprocessing\"\n",
    ")\n",
    "\n",
    "trained_model = preprocessing(raw_data_train)\n"
   ],
   "id": "917119d59139739b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:l_trans_bandwidth must be less than h_freq, setting it to l_freq:0.1Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 3.50 Hz\n",
      "- Upper transition bandwidth: 3.50 Hz\n",
      "- Filter length: 237 samples (0.948 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 31.50 Hz)\n",
      "- Filter length: 8251 samples (33.004 s)\n",
      "\n",
      "Finding events on: STI\n",
      "90 events found on stim channel STI\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "90 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 90 events and 251 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | conv1     | Conv1d           | 1.3 K  | train\n",
      "1 | pool      | MaxPool1d        | 0      | train\n",
      "2 | conv2     | Conv1d           | 10.3 K | train\n",
      "3 | fc        | Linear           | 7.9 K  | train\n",
      "4 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "19.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.6 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\Desktop\\projects\\OpenCortexBCI\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:428: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\Desktop\\projects\\OpenCortexBCI\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:428: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.83it/s, v_num=3]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00, 47.42it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 49.43it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 48.40it/s]\u001B[A\n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.91it/s, v_num=3]       \u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00, 55.77it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 54.60it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 46.59it/s]\u001B[A\n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.52it/s, v_num=3]       \u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00, 42.12it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 18.23it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 21.49it/s]\u001B[A\n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.14it/s, v_num=3]       \u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00, 56.40it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 59.26it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 59.56it/s]\u001B[A\n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.16it/s, v_num=3]       \u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00, 45.57it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 51.36it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 40.83it/s]\u001B[A\n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:05<00:00,  1.61it/s, v_num=3]       \u001B[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:05<00:00,  1.60it/s, v_num=3]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_path = \"example_eegnet.pth\"\n",
    "lightning_node = preprocessing.get_node(\"SimpleEEGNet\")\n",
    "lightning_node.save_checkpoint(model_path)"
   ],
   "id": "395b8a04bda61e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T15:37:37.338502Z",
     "start_time": "2025-10-07T15:37:33.761848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from opencortex.neuroengine.flux.estimation.predict import PredictNode\n",
    "from opencortex.neuroengine.flux.evaluation.metrics import MetricNode\n",
    "\n",
    "\n",
    "fitted_scaler = preprocessing.get_node(\"StdScaler\")\n",
    "extractor_node = preprocessing.get_node(\"XyExtractor\")\n",
    "\n",
    "\n",
    "inference_pipeline = Sequential(\n",
    "    NotchFilterNode((50, 60), name='NotchFilter'),\n",
    "    BandPassFilterNode(0.1, 30.0, name='BandPassFilter'),\n",
    "    ExtractEventsNode(stim_channel='STI', auto_label=True, name='ExtractEvents'),\n",
    "    FilterEventsNode(max_event_id=90, name='FilterEvents'),\n",
    "    RelabelEventsNode(target_class=1, nontarget_label=3, name='RelabelEvents'),\n",
    "    EpochingNode(tmin=-0.2, tmax=0.8, baseline=(-0.1, 0.0), event_id={'T': 1, 'NT': 3}, name='Epoching'),\n",
    "    extractor_node,\n",
    "    fitted_scaler,\n",
    "    DatasetNode(split_size=0.0, batch_size=1, shuffle=False, num_workers=4, name='TestDataset'),\n",
    "    LightningNode(\n",
    "            model=trained_model,\n",
    "            checkpoint_path=model_path,\n",
    "            trainer_config={\n",
    "                'max_epochs': 5,\n",
    "                'accelerator': 'cpu',\n",
    "                'enable_progress_bar': True,\n",
    "                'enable_model_summary': False,\n",
    "            },\n",
    "            mode='inference',\n",
    "            name='SimpleEEGNet'\n",
    "        ),\n",
    "    name=\"Inference\",\n",
    "\n",
    ")\n",
    "\n",
    "predictions = inference_pipeline(raw_data_test)\n",
    "predictions\n"
   ],
   "id": "df0297a659f17bd8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:l_trans_bandwidth must be less than h_freq, setting it to l_freq:0.1Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 3.50 Hz\n",
      "- Upper transition bandwidth: 3.50 Hz\n",
      "- Filter length: 237 samples (0.948 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 31.50 Hz)\n",
      "- Filter length: 8251 samples (33.004 s)\n",
      "\n",
      "Finding events on: STI\n",
      "90 events found on stim channel STI\n",
      "Event IDs: [1 2]\n",
      "Not setting metadata\n",
      "90 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 90 events and 251 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\miche\\Desktop\\projects\\OpenCortexBCI\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:428: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00<00:00, 321.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6eba1d3c177a8fbe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
